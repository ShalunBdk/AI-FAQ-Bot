# CLAUDE.md - AI Assistant Guide for AI-FAQ-Bot

> **Purpose**: Comprehensive context about the AI-FAQ-Bot codebase for AI assistants.

**Last Updated**: 2025-12-18
**Language**: Python 3.11
**Stack**: python-telegram-bot, ChromaDB, sentence-transformers, pymorphy3, Flask, SQLite, OpenRouter API
**Semantic Model**: deepvk/USER2-base (Russian-optimized, 8K context, with task-specific prefixes)
**RAG**: OpenRouter API (GPT-4, Claude, Gemini) with Privacy First anonymization

---

## Project Overview

Multi-platform FAQ bot with **cascading search system** (4 levels) and semantic understanding.

### Key Features

- **Cascading Search (4 levels) + RAG**:
  - ğŸ¯ Exact Match (100%) â†’ ğŸ”‘ Keyword Search with Lemmatization (70-95%) â†’ ğŸ§  Semantic Search (45-70%) â†’ âŒ Fallback
  - Automatic word form recognition (Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ, Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ğ¸ â†’ Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ)
  - ğŸ¤– **RAG Generation** (optional): Smart answer generation via LLM after search
- **Privacy First RAG**:
  - ğŸ”’ PII Anonymization before sending to LLM (emails, phones, names, orgs, locations)
  - ğŸ¤– Answer generation via OpenRouter API (GPT-4, Claude, Gemini, etc.)
  - ğŸ”“ Deanonymization of LLM responses back to original data
  - ğŸ“Š Combining information from multiple FAQs into coherent answer
- **Disambiguation (Ğ£Ñ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ)**:
  - ğŸ”€ Automatic detection of ambiguous queries (when multiple FAQs have similar confidence)
  - âœ… User selects the correct FAQ from presented options
  - Full logging: both the display of options and user selection
- **Multi-Platform**: Telegram + Bitrix24
- **Web Admin Panel**: FAQ management, analytics, settings, keyword optimization
- **Bitrix24 Integration**: OAuth 2.0, iframe embedding, role-based access
- **Hot Reload**: Update FAQ without restarting bots
- **Analytics**: Query logs, similarity scores, search levels, user feedback

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Interfaces                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Telegram    â”‚ Bitrix24    â”‚ Web Admin                  â”‚
â”‚ (port 5001) â”‚ (port 5002) â”‚ (port 5000)                â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Core Search & RAG Layer     â”‚
       â”‚  Cascading Search â†’ LLM       â”‚
       â”‚  Privacy First (Anonymization)â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚     Shared Data Layer         â”‚
       â”‚  SQLite + ChromaDB            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   External Services           â”‚
       â”‚  OpenRouter API (LLM)         â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Directory Structure

```
FAQBot/
â”œâ”€â”€ Dockerfile                     # Docker Ğ¾Ğ±Ñ€Ğ°Ğ· (Python 3.11 + Node.js)
â”œâ”€â”€ docker-compose.dev.yml         # Development ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
â”œâ”€â”€ docker-compose.production.yml  # Production ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ (Bitrix24)
â”œâ”€â”€ nginx.conf.example             # Nginx ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ´Ğ»Ñ Bitrix24
â”œâ”€â”€ docker.env.production          # Ğ¨Ğ°Ğ±Ğ»Ğ¾Ğ½ .env Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½Ğ°
â”œâ”€â”€ README.md                      # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
â”œâ”€â”€ CLAUDE.md                      # AI-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ (ÑÑ‚Ğ¾Ñ‚ Ñ„Ğ°Ğ¹Ğ»)
â”œâ”€â”€ DEPLOY-BITRIX24.md            # Ğ“Ğ°Ğ¹Ğ´ Ğ¿Ğ¾ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ
â”œâ”€â”€ PRODUCTION-CHECKLIST.md       # Ğ§ĞµĞºĞ»Ğ¸ÑÑ‚ Ğ¿ĞµÑ€ĞµĞ´ Ğ´ĞµĞ¿Ğ»Ğ¾ĞµĞ¼
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ database.py        # SQLite ORM, settings, logging
â”‚   â”‚   â”œâ”€â”€ search.py          # Cascading search (4 levels)
â”‚   â”‚   â”œâ”€â”€ llm_service.py     # RAG: LLM generation via OpenRouter
â”‚   â”‚   â”œâ”€â”€ pii_anonymizer.py  # RAG: Privacy First anonymization
â”‚   â”‚   â””â”€â”€ logging_config.py  # UTC+7 logging
â”‚   â”œâ”€â”€ bots/
â”‚   â”‚   â”œâ”€â”€ bot.py             # Telegram bot (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹)
â”‚   â”‚   â””â”€â”€ b24_bot.py         # Bitrix24 bot (Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ b24_api.py         # Bitrix24 REST client
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ web_admin.py       # Flask admin panel
â”‚       â”œâ”€â”€ middleware.py      # Auth & CORS
â”‚       â”œâ”€â”€ bitrix24_*.py      # OAuth, permissions
â”‚       â””â”€â”€ templates/admin/   # HTML templates
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ migrate_*.py           # Database migrations
â”‚   â”œâ”€â”€ test_cascade_search.py # Search system tests
â”‚   â”œâ”€â”€ test_rag_pipeline.py   # RAG pipeline tests
â”‚   â”œâ”€â”€ demo_faq.py            # Demo data (21 FAQs)
â”‚   â””â”€â”€ register_bot.py        # Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ² Bitrix24
â”‚
â”œâ”€â”€ docs/                      # Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
â”‚   â”œâ”€â”€ RAG_GUIDE.md           # RAG (Privacy First) guide
â”‚   â”œâ”€â”€ QUICKSTART_RAG.md      # RAG quick start
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â”œâ”€â”€ DOCKER.md
â”‚   â”œâ”€â”€ QUICKSTART.md
â”‚   â”œâ”€â”€ DOCKER-CPU-OPTIMIZATION.md
â”‚   â”œâ”€â”€ REVERSE-PROXY-SETUP.md
â”‚   â””â”€â”€ migrations/            # Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹ Ğ‘Ğ”
â”‚
â”œâ”€â”€ nginx/                     # ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ nginx ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ .dockerignore              # Docker build ignore rules
â””â”€â”€ docker-compose.override.yml.example  # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ´Ğ»Ñ ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
```

---

## Core Components

### 1. Cascading Search (`src/core/search.py`)

**4-level search with automatic fallback:**

```
Level 1: EXACT MATCH    â†’ 100% (normalized text comparison)
Level 2: KEYWORD SEARCH â†’ 70-95% (short queries â‰¤5 words, with lemmatization)
Level 3: SEMANTIC SEARCH â†’ 45-70% (ChromaDB vectors with deepvk/USER2-base)
Level 4: FALLBACK       â†’ 0% (polite refusal)
```

**Semantic Model (deepvk/USER2-base):**
- **Russian-optimized** transformer (149M parameters) from deepvk
- **Long context support**: 8,192 tokens (vs 512 in old model)
- **Task-specific prefixes**: Uses `search_query:` and `search_document:` for optimal retrieval
- **Improved accuracy**: Better understanding of rephrased questions and typos
- **Usage**:
  - Queries: `collection.query(query_texts=[f"search_query: {text}"])`
  - Documents: `documents.append(f"search_document: {text}")`
- **Note**: All documents in ChromaDB must be re-indexed after model change

**Lemmatization (pymorphy3):**
- Automatic word form normalization (Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ, Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ğ¸ â†’ Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ)
- Applied to both user queries and FAQ keywords
- Functions: `lemmatize_word()`, `lemmatize_text()`, `extract_keywords()`
- Reduces need for manual word form variants

**Main function:**
```python
from src.core.search import find_answer, SearchResult

result = find_answer(query_text, collection, settings)
# Returns: SearchResult(found, faq_id, question, answer, confidence, search_level, ...)
```

**Settings** (in `bot_settings` table):
- `exact_match_threshold`: "95"
- `keyword_match_threshold`: "70"
- `semantic_match_threshold`: "45"
- `keyword_search_max_words`: "5"
- `fallback_message`: "..."

**Icons**: ğŸ¯ exact, ğŸ”‘ keyword, ğŸ§  semantic, ğŸ”€ disambiguation_shown, âœ… disambiguation, ğŸ“„ direct, âŒ none

**Disambiguation (Ğ Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ¾Ğ´Ğ½Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚ĞµĞ¹):**

When multiple FAQs have similar confidence scores (difference < 7%), the system enters disambiguation mode:

1. **Detection Logic** (`src/core/search.py`):
   - Triggered when top-2 results have confidence difference < 7%
   - Returns `SearchResult` with `ambiguous=True` and `alternatives` list
   - Works for both keyword search and semantic search levels
   - **Limits**: Max 3 alternatives, only variants within 12% from top result

2. **User Interaction** (both platforms):
   - Bot sends message: "ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ². Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¹:"
   - Shows buttons with FAQ questions (without confidence %) for clean UX
   - User clicks button to select the correct FAQ

3. **Logging** (with real confidence):
   - **Step 1**: `search_level='disambiguation_shown'`, `faq_id=NULL` - options presented with confidence %
     - Example: `- [83.6%] ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ñ ĞºĞ°Ñ€Ñ‚Ñ€Ğ¸Ğ´Ğ¶ĞµĞ¼\n- [74.3%] ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ Ğ¿Ñ€Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¾Ğ¼`
   - **Step 2**: `search_level='disambiguation'`, `faq_id=selected`, `confidence=real_value` - user choice
     - **Important**: Uses REAL confidence from search (not 100%), e.g., 83.6%
   - Both steps linked via `query_log_id`

4. **UI Behavior**:
   - **Bitrix24**: Message is EDITED to show selected FAQ (no "Message deleted" stub)
   - **Telegram**: Message is edited to show selected FAQ (removes buttons)
   - **Admin logs**:
     - `disambiguation_shown` hidden if user selected
     - Click on "ğŸ”€ ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ğ½Ñ‹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ°" expands details with confidence %

5. **Analytics**:
   - Disambiguation is **excluded** from "no answer" / "failed queries" statistics
   - Tracked separately in search level distribution
   - Functions updated: `get_logs()`, `get_statistics()`, `get_period_statistics()`, `get_failed_queries_for_period()`

**Implementation Files**:
- `src/core/search.py`: Detection logic (lines 327-566)
- `src/bots/bot.py`: Telegram UI (lines 467-500, 671-731)
- `src/bots/b24_bot.py`: Bitrix24 UI (lines 484-516, 815-868)
- `src/web/templates/admin/logs.html`: Frontend filtering (lines 441-464)
- `src/core/database.py`: SQL exclusions (lines 626, 717-724, 1373-1381, 1518-1520)

### 2. RAG (Retrieval-Augmented Generation) (`src/core/llm_service.py` + `src/core/pii_anonymizer.py`)

**Privacy First RAG architecture with PII anonymization:**

```
User Query â†’ Cascading Search â†’ [RAG ENABLED?]
                                      â†“
                         1. Prepare context from found FAQs
                         2. Anonymize PII (PiiAnonymizer)
                         3. Send to LLM (OpenRouter API)
                         4. Deanonymize response
                         5. Return to user
```

**Key Components:**

#### PiiAnonymizer (`src/core/pii_anonymizer.py`)

**Purpose:** Protect personal data before sending to cloud LLM.

**Anonymization layers:**
1. **BB-code URLs** (regex) - `[URL=...]text[/URL]` â†’ `[URL_1]` (protects employee profiles)
2. **Emails** (regex) - `ivan@example.com` â†’ `[EMAIL_1]`
3. **Phones** (regex) - `+7 (999) 123-45-67` â†’ `[PHONE_1]`
4. **NER (natasha)** - DISABLED (too many false positives, protected via BB URL anonymization)

**Usage:**
```python
from src.core.pii_anonymizer import PiiAnonymizer

anonymizer = PiiAnonymizer()
anonymized, mapping = anonymizer.anonymize("Ğ—Ğ²Ğ¾Ğ½Ğ¸Ñ‚Ğµ Ğ˜Ğ²Ğ°Ğ½Ñƒ: ivan@corp.com")
# anonymized: "Ğ—Ğ²Ğ¾Ğ½Ğ¸Ñ‚Ğµ [PER_1]: [EMAIL_1]"
# mapping: {"[PER_1]": "Ğ˜Ğ²Ğ°Ğ½Ñƒ", "[EMAIL_1]": "ivan@corp.com"}

original = anonymizer.deanonymize(anonymized, mapping)
# original: "Ğ—Ğ²Ğ¾Ğ½Ğ¸Ñ‚Ğµ Ğ˜Ğ²Ğ°Ğ½Ñƒ: ivan@corp.com"
```

#### LLMService (`src/core/llm_service.py`)

**Purpose:** Generate smart answers via LLM with anonymization.

**Features:**
- OpenRouter API integration (access to GPT-4, Claude, Gemini, etc.)
- Automatic PII anonymization/deanonymization
- Context preparation from multiple FAQs
- Customizable system prompt with department routing
- Token usage tracking

**Main method:**
```python
from src.core.llm_service import LLMService

service = LLMService()
answer, metadata = service.generate_answer(
    user_question="ĞšĞ°Ğº ÑĞ²ÑĞ·Ğ°Ñ‚ÑŒÑÑ Ñ Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸ĞµĞ¹?",
    db_chunks=[
        {
            'question': 'ĞšĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ñ‹ Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ğ¸',
            'answer': 'Ğ‘ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ñ: ĞœĞ°Ñ€Ğ¸Ñ, Ñ‚ĞµĞ». +7 495 123-45-67',
            'confidence': 92.3
        }
    ],
    max_tokens=1024,
    temperature=0.3
)
# Returns: (generated_answer, metadata with tokens/pii info)
```

**System Prompt highlights:**
- Uses department routing knowledge base (23 departments)
- Strict rules: answer only from context, don't hallucinate
- Preserves placeholders (`[PER_1]`, `[EMAIL_1]`) as-is
- Builds logical conclusions from context

**Integration in bots:**
- `src/bots/bot.py` (Telegram): lines 527-596
- `src/bots/b24_bot.py` (Bitrix24): lines 481-559
- Triggered AFTER cascading search finds results
- Automatic fallback to regular answer on LLM errors
- When RAG enabled, disambiguation bypassed (LLM combines multiple FAQs)

**Configuration (.env):**
```env
RAG_ENABLED=true                     # enable/disable RAG
OPENROUTER_API_KEY=sk-or-v1-xxx     # OpenRouter API key
OPENROUTER_MODEL=openai/gpt-4o-mini # LLM model
RAG_MAX_TOKENS=1024                  # max tokens in response
RAG_TEMPERATURE=0.3                  # generation temperature (0.0-1.0)
RAG_MIN_RELEVANCE_SCORE=45.0         # min confidence to use RAG
RAG_MAX_CHUNKS=5                     # max FAQs in context
```

**Recommended models:**
- `google/gemini-2.0-flash-001` - FREE, good quality
- `openai/gpt-4o-mini` - $0.15/$0.60 per 1M tokens (production recommended)
- `openai/gpt-4o` - $2.50/$10.00 per 1M tokens (high quality)
- `anthropic/claude-3.5-sonnet` - $3.00/$15.00 per 1M tokens

**Testing:**
```bash
python scripts/test_rag_pipeline.py
```

See `docs/RAG_GUIDE.md` for complete documentation.

### 3. Database (`src/core/database.py`)

**Key functions:**
```python
# FAQ
get_all_faqs(), get_faq_by_id(id), add_faq(...), update_faq(...), delete_faq(id)

# Logging
add_query_log(user_id, username, query_text, platform) â†’ int
add_answer_log(query_log_id, faq_id, similarity, answer, search_level) â†’ int
add_rating_log(answer_log_id, user_id, rating) â†’ int

# Settings
get_bot_setting(key), update_bot_setting(key, value), get_bot_settings() â†’ Dict

# Analytics
get_logs(filters), get_statistics(filters), get_search_level_statistics()

# Test Periods
create_test_period(name, description) â†’ int
end_test_period(period_id) â†’ bool
get_test_periods() â†’ List[Dict]
get_active_test_period() â†’ Dict
archive_current_logs(period_id) â†’ Dict
clear_unarchived_logs() â†’ Dict
get_period_statistics(period_id) â†’ Dict
get_failed_queries_for_period(period_id, limit) â†’ List[Dict]
```

**Tables:**
- `faq` (id, category, question, answer, keywords)
- `query_logs` (user_id, username, query_text, platform, timestamp, period_id)
- `answer_logs` (query_log_id, faq_id, similarity_score, answer_shown, search_level, period_id)
- `rating_logs` (answer_log_id, user_id, rating, period_id)
- `bot_settings` (key, value)
- `bitrix24_permissions` (domain, user_id, role)
- `test_periods` (id, name, description, start_date, end_date, status)

**Note on RAG:** RAG-generated answers are stored in `answer_logs.answer_shown` field. Search level remains original (exact/keyword/semantic), not "rag".

### 4. Bots

**Telegram** (`src/bots/bot.py`):
- Long-polling + Flask reload server (port 5001)
- User-level rate limiting, callback debouncing
- `POST /reload` - hot reload ChromaDB

**Bitrix24** (`src/bots/b24_bot.py`):
- Webhook-based Flask app (port 5002)
- Events: `ONIMBOTMESSAGEADD`, `ONIMCOMMANDADD`, `ONIMBOTJOINCHAT`
- BB-code formatting for messages

**RAG Integration (both bots):**
- Triggered after cascading search finds result (confidence >= RAG_MIN_RELEVANCE_SCORE)
- Ğ›ĞµĞ½Ğ¸Ğ²Ğ°Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ LLM ÑĞµÑ€Ğ²Ğ¸ÑĞ° Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸
- Automatic fallback to regular answer on errors
- When disambiguation detected and RAG enabled â†’ uses all alternatives for context

### 5. Web Admin (`src/web/web_admin.py`)

**Routes:**
- `GET/POST /admin/` - FAQ management
- `GET /admin/logs` - Analytics
- `GET /admin/test-periods` - Test periods management & statistics
- `GET/POST /admin/settings` - Bot settings
- `POST /admin/retrain` - Rebuild ChromaDB + notify bots
- `POST /admin/api/optimize-keywords` - Lemmatize and deduplicate keywords
- `GET /admin/api/search-level-stats` - Cascade search statistics
- `GET /admin/api/test-periods/list` - Get all test periods
- `POST /admin/api/test-periods/create` - Create new test period
- `POST /admin/api/test-periods/{id}/end` - End test period
- `POST /admin/api/test-periods/{id}/archive` - Archive logs
- `GET /admin/api/test-periods/{id}/statistics` - Get period statistics
- `GET /admin/api/test-periods/{id}/export?format=excel|json|csv` - Export report
- `GET /admin/api/test-periods/{id}/failed-queries` - Get failed queries

**UI Features:**
- "Optimize" button in FAQ form - automatically removes duplicate word forms
- Toast notifications for user feedback
- Keyword optimization statistics display

**Static Assets:**
- Uses local Tailwind CSS (no CDN)
- Local fonts: Inter, Material Symbols Outlined
- Build: `npm run build:css` â†’ `src/web/static/css/output.css`
- Watch mode: `npm run watch:css`
- See `README_ASSETS.md` for details

---

## Code Conventions

| Type | Convention | Example |
|------|-----------|---------|
| Modules | snake_case | `web_admin.py` |
| Classes | PascalCase | `SearchResult` |
| Functions | snake_case | `find_answer()` |
| Constants | UPPER_SNAKE | `SIMILARITY_THRESHOLD` |
| DB tables | snake_case | `query_logs` |

**Comments**: Russian for business logic, English docstrings.

**Error handling**: Always use `get_db_connection()` context manager, `safe_send_message()` wrapper.

---

## Common Tasks

### Add FAQ
```python
from src.core.database import add_faq
from src.web.web_admin import retrain_chromadb, notify_bot_reload

add_faq(category, question, answer, keywords)
retrain_chromadb()
notify_bot_reload()
```

### Optimize keywords programmatically
```python
from src.core.search import lemmatize_word

keywords = ["Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ", "Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ğ¸", "Ñ‚Ğ¾Ğ²Ğ°Ñ€", "Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹"]
optimized = list(dict.fromkeys([lemmatize_word(kw) for kw in keywords]))
# Result: ["Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ", "Ñ‚Ğ¾Ğ²Ğ°Ñ€"]
```

Or use the web UI "Optimize" button in FAQ form.

### Test disambiguation behavior
```python
from src.core.search import find_answer

# Create two FAQs with overlapping keywords for testing
# FAQ 1: "ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ñ‡Ñ‚Ğ¾Ğ¹" - keywords: "Ğ¿Ğ¸ÑÑŒĞ¼Ğ¾, Ğ¿Ğ¾Ñ‡Ñ‚Ğ°, email"
# FAQ 2: "ĞšĞ°Ğº Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ¸ÑÑŒĞ¼Ğ¾ Ğ¿Ğ¾Ñ‡Ñ‚Ğ¾Ğ¹ Ğ Ğ¾ÑÑĞ¸Ğ¸" - keywords: "Ğ¿Ğ¸ÑÑŒĞ¼Ğ¾, Ğ¿Ğ¾Ñ‡Ñ‚Ğ°, Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ°"

# Query that triggers disambiguation
result = find_answer("Ğ¿Ğ¸ÑÑŒĞ¼Ğ¾ Ğ¿Ğ¾Ñ‡Ñ‚Ğ¾Ğ¹", collection, settings)

# Check if disambiguation was triggered
if result.ambiguous:
    print(f"Disambiguation triggered! {len(result.alternatives)} alternatives:")
    for alt in result.alternatives:
        print(f"  - {alt['question']} ({alt['confidence']:.1f}%)")
    # Bot will show buttons for user to choose
```

**Note**: Disambiguation is triggered when:
- Top-2 results have confidence difference < 15%
- Applies to both keyword and semantic search levels
- User selection is logged as `search_level='disambiguation'`

### Add new setting
1. Add to `DEFAULT_BOT_SETTINGS` in `database.py`
2. Add UI field in `settings.html`
3. Use: `get_bot_setting("key")`

### Run cascade search tests
```bash
source venv/Scripts/activate
python scripts/test_cascade_search.py
```

### Manage test periods
```python
from src.core.database import (
    create_test_period, end_test_period,
    archive_current_logs, clear_unarchived_logs,
    get_period_statistics
)

# Create test period
period_id = create_test_period("Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° #1", "ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ")

# During testing, logs are automatically linked to active period

# Archive logs
archive_current_logs(period_id)

# End period
end_test_period(period_id)

# Get statistics
stats = get_period_statistics(period_id)

# Clear unarchived logs (before production launch)
clear_unarchived_logs()
```

See `docs/TEST_PERIODS_GUIDE.md` for detailed workflow.

### Database Migrations
**Ğ’ÑĞµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°ÑÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸** Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ Ñ‡ĞµÑ€ĞµĞ· `init_database()`.

ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² `scripts/migrate_*.py` Ğ½ÑƒĞ¶Ğ½Ñ‹ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ:
- ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ **ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ…** Ğ±Ğ°Ğ· (Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº/Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†)
- Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (history Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ ÑÑ…ĞµĞ¼Ñ‹)

ĞŸÑ€Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğ¼ Ñ€Ğ°Ğ·Ğ²Ñ‘Ñ€Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ **Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ÑÑ**.

---

## Configuration

### Environment (.env)
```env
# Required
TELEGRAM_TOKEN=...

# Semantic Model (IMPORTANT: Change requires ChromaDB re-indexing)
MODEL_NAME=deepvk/USER2-base
SIMILARITY_THRESHOLD=45

# Bitrix24
BITRIX24_WEBHOOK=https://...
BITRIX24_BOT_ID=62
BITRIX24_CLIENT_ID=...

# RAG (Optional - for smart answer generation)
RAG_ENABLED=true
OPENROUTER_API_KEY=sk-or-v1-xxx
OPENROUTER_MODEL=openai/gpt-4o-mini
RAG_MAX_TOKENS=1024
RAG_TEMPERATURE=0.3
RAG_MIN_RELEVANCE_SCORE=45.0
RAG_MAX_CHUNKS=5
```

### Cascade Search Settings (bot_settings table)
| Key | Default | Description |
|-----|---------|-------------|
| exact_match_threshold | 95 | Exact match minimum |
| keyword_match_threshold | 70 | Keyword search minimum |
| semantic_match_threshold | 45 | Semantic search minimum |
| keyword_search_max_words | 5 | Max words for keyword search |
| fallback_message | ... | Custom fallback text |

### RAG Settings (.env variables)
| Key | Default | Description |
|-----|---------|-------------|
| RAG_ENABLED | true | Enable/disable RAG generation |
| OPENROUTER_API_KEY | - | OpenRouter API key (REQUIRED if RAG enabled) |
| OPENROUTER_MODEL | openai/gpt-4o-mini | LLM model to use |
| RAG_MAX_TOKENS | 1024 | Max tokens in LLM response |
| RAG_TEMPERATURE | 0.3 | Generation temperature (0.0-1.0) |
| RAG_MIN_RELEVANCE_SCORE | 45.0 | Min confidence to trigger RAG |
| RAG_MAX_CHUNKS | 5 | Max FAQs in context |

---

## Quick Reference

### Ports
| Service | Port | Endpoint |
|---------|------|----------|
| Web Admin | 5000 | http://localhost:5000 |
| Telegram Bot | 5001 | /reload |
| Bitrix24 Bot | 5002 | /webhook/bitrix24 |

### Key Files
| Purpose | File |
|---------|------|
| Cascading search | `src/core/search.py` |
| RAG LLM service | `src/core/llm_service.py` |
| RAG PII anonymization | `src/core/pii_anonymizer.py` |
| Database ORM | `src/core/database.py` |
| Telegram bot | `src/bots/bot.py` |
| Bitrix24 bot | `src/bots/b24_bot.py` |
| Web admin | `src/web/web_admin.py` |

### Docker
```bash
# Development (Ğ²ÑĞµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹)
docker-compose -f docker-compose.dev.yml up -d

# Production (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Bitrix24)
docker-compose -f docker-compose.production.yml up -d

# Production Ñ Telegram (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
docker-compose -f docker-compose.production.yml --profile telegram up -d
```

---

## Important Constraints

1. **SQLite is single-writer** - use transactions carefully
2. **ChromaDB must be synced** - always call `retrain_chromadb()` + `notify_bot_reload()` after FAQ changes
3. **Timezone**: Store UTC, display UTC+7 via `convert_utc_to_utc7()`
4. **Platform field required**: 'telegram', 'bitrix24', or 'web' in all logs
5. **Keywords are comma-separated strings** (not JSON)

---

## AI Assistant Guidelines

**DO:**
- âœ… Use Russian comments for business logic
- âœ… Call `retrain_chromadb()` + `notify_bot_reload()` after FAQ changes
- âœ… Use `get_db_connection()` context manager
- âœ… Log with `search_level` parameter in `add_answer_log()`
- âœ… Test both Telegram and Bitrix24 after changes
- âœ… Use lemmatized keywords (base forms) instead of listing all variants
- âœ… Exclude `disambiguation_shown` and `disambiguation` from "no answer" / "failed queries" filters
- âœ… Use `search_query:` prefix for queries and `search_document:` for documents (deepvk/USER2-base)
- âœ… Save REAL confidence in disambiguation logs (not 100%)
- âœ… Use RAG for improving answer quality when confidence >= RAG_MIN_RELEVANCE_SCORE
- âœ… Always anonymize PII before sending to LLM (automatic in LLMService)
- âœ… Test RAG pipeline with `scripts/test_rag_pipeline.py`

**DON'T:**
- âŒ Store UTC+7 directly (store UTC)
- âŒ Modify schema without migration script
- âŒ Update FAQs without retraining ChromaDB
- âŒ Use `time.sleep()` in async functions
- âŒ Add all word forms manually (use lemmatization)
- âŒ Count disambiguation as failed queries in statistics
- âŒ Forget prefixes when using deepvk/USER2-base model
- âŒ Send raw PII to LLM (always use LLMService which handles anonymization)
- âŒ Hardcode OpenRouter API key (use environment variable)
- âŒ Use RAG for low-confidence results (< RAG_MIN_RELEVANCE_SCORE)

---

**Document Version**: 3.0 (deepvk/USER2-base + Improved Disambiguation + Enhanced Logging + Privacy First RAG)
