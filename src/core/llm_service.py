# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å RAG (Retrieval-Augmented Generation) —Å Privacy First –ø–æ–¥—Ö–æ–¥–æ–º

–†–µ–∞–ª–∏–∑—É–µ—Ç:
- –ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—é –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ LLM
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ OpenRouter API
- –î–µ–∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤
"""

import logging
import os
import time
from typing import List, Dict, Optional, Tuple
from openai import OpenAI
from datetime import datetime

from src.core.pii_anonymizer import PiiAnonymizer

logger = logging.getLogger(__name__)


class LLMService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM —Å Privacy First –ø–æ–¥—Ö–æ–¥–æ–º

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenRouter API –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º LLM –º–æ–¥–µ–ª—è–º
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        base_url: str = "https://openrouter.ai/api/v1"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM —Å–µ—Ä–≤–∏—Å–∞

        Args:
            api_key: OpenRouter API –∫–ª—é—á (–µ—Å–ª–∏ None - –±–µ—Ä–µ—Ç—Å—è –∏–∑ OPENROUTER_API_KEY)
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None - –±–µ—Ä–µ—Ç—Å—è –∏–∑ OPENROUTER_MODEL –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç)
            base_url: Base URL –¥–ª—è OpenRouter API
        """
        # API –∫–ª—é—á
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            logger.error("OPENROUTER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
            raise ValueError("OPENROUTER_API_KEY –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã LLM —Å–µ—Ä–≤–∏—Å–∞")

        # –ú–æ–¥–µ–ª—å
        self.model = model or os.getenv("OPENROUTER_MODEL", "openai/gpt-4o-mini")
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LLM –º–æ–¥–µ–ª—å: {self.model}")

        # Retry –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ —á–µ—Ä–µ–∑ env)
        self.max_retries = int(os.getenv("OPENROUTER_MAX_RETRIES", "3"))
        self.retry_delay = int(os.getenv("OPENROUTER_RETRY_DELAY", "2"))
        logger.debug(f"Retry –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {self.max_retries} –ø–æ–ø—ã—Ç–æ–∫, –Ω–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ {self.retry_delay}—Å")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç (—Å–æ–≤–º–µ—Å—Ç–∏–º —Å OpenRouter)
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=base_url
        )

        # –ê–Ω–æ–Ω–∏–º–∞–π–∑–µ—Ä
        self.anonymizer = PiiAnonymizer()

        # –ö—ç—à —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ reload_prompt)
        self._system_prompt_cache = None
        self.reload_prompt()

    def reload_prompt(self):
        """
        –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –ë–î –≤ –∫—ç—à

        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∏ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —á–µ—Ä–µ–∑ –∞–¥–º–∏–Ω–∫—É
        """
        from src.core.database import get_bot_setting, DEFAULT_BOT_SETTINGS

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ç–¥–µ–ª—ã –∏ –ø—Ä–æ–º–ø—Ç –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        departments_info = get_bot_setting("rag_departments_info") or DEFAULT_BOT_SETTINGS.get("rag_departments_info", "")
        system_prompt_template = get_bot_setting("rag_system_prompt") or DEFAULT_BOT_SETTINGS.get("rag_system_prompt", "")

        # –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –æ—Ç–¥–µ–ª—ã –≤ –ø—Ä–æ–º–ø—Ç
        self._system_prompt_cache = system_prompt_template.replace("{DEPARTMENTS_INFO}", departments_info)

        logger.info("‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç RAG –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫")

    def _get_system_prompt(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –∫—ç—à–∞"""
        if self._system_prompt_cache is None:
            self.reload_prompt()
        return self._system_prompt_cache

    def _prepare_context(self, chunks: List[Dict]) -> str:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤

        Args:
            chunks: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏: question, answer, confidence

        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
        """
        if not chunks:
            return ""

        context_parts = []

        for i, chunk in enumerate(chunks, 1):
            question = chunk.get('question', '')
            answer = chunk.get('answer', '')
            confidence = chunk.get('confidence', 0)

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫
            context_parts.append(
                f"–î–æ–∫—É–º–µ–Ω—Ç {i} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {confidence:.1f}%):\n"
                f"–í–æ–ø—Ä–æ—Å: {question}\n"
                f"–û—Ç–≤–µ—Ç: {answer}\n"
            )

        context = "\n---\n".join(context_parts)

        logger.debug(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ {len(chunks)} —á–∞–Ω–∫–æ–≤ (–¥–ª–∏–Ω–∞: {len(context)} —Å–∏–º–≤–æ–ª–æ–≤)")

        return context

    def generate_answer(
        self,
        user_question: str,
        db_chunks: List[Dict],
        max_tokens: int = 1024,
        temperature: float = 0.3
    ) -> Tuple[str, Dict[str, any]]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM —Å –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–µ–π PII

        –ü—Ä–æ—Ü–µ—Å—Å:
        1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ —á–∞–Ω–∫–æ–≤
        2. –ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –≤–æ–ø—Ä–æ—Å–∞
        3. –ó–∞–ø—Ä–æ—Å –∫ LLM
        4. –î–µ–∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞

        Args:
            user_question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            db_chunks: –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ ChromaDB
                      –§–æ—Ä–º–∞—Ç: [{"question": "...", "answer": "...", "confidence": 85.5}, ...]
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.0 - –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, 1.0 - –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π)

        Returns:
            Tuple (answer, metadata)
            - answer: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (–¥–µ–∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
            - metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–º–æ–¥–µ–ª—å, —Ç–æ–∫–µ–Ω—ã, –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –∏ —Ç.–¥.)
        """
        try:
            logger.info(f"ü§ñ RAG –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{user_question}'")
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω–æ {len(db_chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
            now = datetime.now()
            days = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"]
            current_date_str = f"{now.strftime('%d.%m.%Y')} ({days[now.weekday()]})"

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (hot reload)
            system_prompt = self._get_system_prompt()

            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –¥–∞—Ç–æ–π
            full_system_prompt = f"–°–ï–ì–û–î–ù–Ø–®–ù–Ø–Ø –î–ê–¢–ê: {current_date_str}\n\n{system_prompt}"

            # –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context = self._prepare_context(db_chunks)

            if not context:
                logger.warning("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—É—Å—Ç! –í–æ–∑–≤—Ä–∞—â–∞–µ–º fallback –æ—Ç–≤–µ—Ç.")
                return (
                    "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à–µ–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.",
                    {"error": "empty_context"}
                )

            # –®–∞–≥ 2: –ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            logger.debug("–ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
            anonymized_context, context_mapping = self.anonymizer.anonymize(context)

            # –®–∞–≥ 3: –ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–∞
            logger.debug("–ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–∞...")
            anonymized_question, question_mapping = self.anonymizer.anonymize(user_question)

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥–∏
            combined_mapping = {**context_mapping, **question_mapping}

            logger.info(f"–ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–∞–π–¥–µ–Ω–æ PII: {len(combined_mapping)} —Å—É—â–Ω–æ—Å—Ç–µ–π")

            # –®–∞–≥ 4: –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
            messages = [
                {"role": "system", "content": full_system_prompt}, 
                {"role": "user", "content": f"–ö–û–ù–¢–ï–ö–°–¢:\n{anonymized_context}\n\n–í–û–ü–†–û–°: {anonymized_question}"}
            ]

            logger.debug(f"–ó–∞–ø—Ä–æ—Å –∫ LLM –º–æ–¥–µ–ª–∏: {self.model}")

            # –®–∞–≥ 5: –ó–∞–ø—Ä–æ—Å –∫ OpenRouter —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
            retry_delay = self.retry_delay  # –Ω–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞

            for attempt in range(1, self.max_retries + 1):
                try:
                    logger.debug(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt}/{self.max_retries} –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenRouter...")

                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=messages,
                        max_tokens=max_tokens,
                        temperature=temperature
                    )

                    logger.debug(f"‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt}")
                    break  # –£—Å–ø–µ—Ö, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞

                except Exception as e:
                    error_msg = str(e)

                    if attempt < self.max_retries:
                        logger.warning(
                            f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{self.max_retries} –Ω–µ —É–¥–∞–ª–∞—Å—å: {error_msg}. "
                            f"–ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {retry_delay} —Å–µ–∫—É–Ω–¥..."
                        )
                        time.sleep(retry_delay)
                        retry_delay *= 2  # Exponential backoff: 2s, 4s, 8s, ...
                    else:
                        logger.error(f"‚ùå –í—Å–µ {self.max_retries} –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenRouter –Ω–µ —É–¥–∞–ª–∏—Å—å")
                        raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫

            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
            anonymized_answer = response.choices[0].message.content

            logger.debug(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM (–¥–ª–∏–Ω–∞: {len(anonymized_answer)} —Å–∏–º–≤–æ–ª–æ–≤)")

            # –®–∞–≥ 6: –î–µ–∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            logger.debug("–î–µ–∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
            final_answer = self.anonymizer.deanonymize(anonymized_answer, combined_mapping)

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                "model": self.model,
                "chunks_used": len(db_chunks),
                "pii_found": len(combined_mapping),
                "tokens_used": {
                    "prompt": response.usage.prompt_tokens,
                    "completion": response.usage.completion_tokens,
                    "total": response.usage.total_tokens
                },
                "finish_reason": response.choices[0].finish_reason
            }

            logger.info(f"‚úÖ RAG –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞. –¢–æ–∫–µ–Ω–æ–≤: {metadata['tokens_used']['total']}, PII: {metadata['pii_found']}")

            return final_answer, metadata

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ RAG –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}", exc_info=True)
            return (
                "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                {"error": str(e)}
            )


# ========== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ==========

def generate_rag_answer(
    user_question: str,
    db_chunks: List[Dict],
    api_key: Optional[str] = None,
    model: Optional[str] = None
) -> Tuple[str, Dict[str, any]]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ RAG –æ—Ç–≤–µ—Ç–∞

    Args:
        user_question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        db_chunks: –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
        api_key: OpenRouter API –∫–ª—é—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        Tuple (answer, metadata)
    """
    service = LLMService(api_key=api_key, model=model)
    return service.generate_answer(user_question, db_chunks)
