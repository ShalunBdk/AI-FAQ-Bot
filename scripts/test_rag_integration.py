#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è RAG –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ RAG –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
"""

import sys
import os
import json

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.core import database

def test_rag_logging():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ RAG –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""

    print("üß™ –¢–ï–°–¢: RAG Logging Integration\n")
    print("=" * 60)

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü—ã llm_generations
    print("\nüìã 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã llm_generations...")
    try:
        with database.get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='llm_generations'")
            table_exists = cursor.fetchone()

            if table_exists:
                print("   ‚úÖ –¢–∞–±–ª–∏—Ü–∞ llm_generations —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

                # –ü–æ–ª—É—á–∞–µ–º —Å—Ö–µ–º—É
                cursor.execute("PRAGMA table_info(llm_generations)")
                columns = cursor.fetchall()
                print(f"   ‚úÖ –ö–æ–ª–æ–Ω–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ: {len(columns)}")

                expected_columns = [
                    'id', 'answer_log_id', 'model', 'chunks_used', 'chunks_data',
                    'pii_detected', 'tokens_prompt', 'tokens_completion', 'tokens_total',
                    'finish_reason', 'generation_time_ms', 'error_message', 'created_at'
                ]

                actual_columns = [col[1] for col in columns]
                missing = set(expected_columns) - set(actual_columns)

                if missing:
                    print(f"   ‚ùå –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing}")
                    return False
                else:
                    print("   ‚úÖ –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
            else:
                print("   ‚ùå –û–®–ò–ë–ö–ê: –¢–∞–±–ª–∏—Ü–∞ llm_generations –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
                print("   üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/migrate_add_llm_generations.py")
                return False
    except Exception as e:
        print(f"   ‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ç–∞–±–ª–∏—Ü—ã: {e}")
        return False

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ add_llm_generation_log
    print("\nüìù 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ add_llm_generation_log...")
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_chunks = [
            {"faq_id": "1", "question": "–¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å 1", "confidence": 85.5},
            {"faq_id": "2", "question": "–¢–µ—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å 2", "confidence": 72.3}
        ]

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π query_log
        query_log_id = database.add_query_log(
            user_id=999999,
            username="test_user",
            query_text="–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è RAG",
            platform="web"
        )

        if not query_log_id:
            print("   ‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å query_log")
            return False

        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω query_log (ID: {query_log_id})")

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π answer_log
        answer_log_id = database.add_answer_log(
            query_log_id=query_log_id,
            faq_id=1,
            similarity_score=85.5,
            answer_shown="–¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç —Å RAG –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π",
            search_level="semantic"
        )

        if not answer_log_id:
            print("   ‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å answer_log")
            return False

        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω answer_log (ID: {answer_log_id})")

        # –õ–æ–≥–∏—Ä—É–µ–º RAG –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        llm_gen_id = database.add_llm_generation_log(
            answer_log_id=answer_log_id,
            model="openai/gpt-4o-mini",
            chunks_used=2,
            chunks_data=test_chunks,
            pii_detected=0,
            tokens_prompt=150,
            tokens_completion=95,
            tokens_total=245,
            finish_reason="stop",
            generation_time_ms=1250,
            error_message=None
        )

        if llm_gen_id:
            print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–∞ RAG –∑–∞–ø–∏—Å—å (ID: {llm_gen_id})")
        else:
            print("   ‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å RAG –∑–∞–ø–∏—Å—å")
            return False

    except Exception as e:
        print(f"   ‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return False

    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print("\nüîç 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    try:
        with database.get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT
                    lg.*,
                    al.similarity_score,
                    ql.query_text
                FROM llm_generations lg
                LEFT JOIN answer_logs al ON lg.answer_log_id = al.id
                LEFT JOIN query_logs ql ON al.query_log_id = ql.id
                WHERE lg.id = ?
            """, (llm_gen_id,))

            row = cursor.fetchone()

            if not row:
                print("   ‚ùå –û–®–ò–ë–ö–ê: –ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False

            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–∞ –∑–∞–ø–∏—Å—å:")
            print(f"      - Model: {row['model']}")
            print(f"      - Chunks used: {row['chunks_used']}")
            print(f"      - Tokens: {row['tokens_prompt']} + {row['tokens_completion']} = {row['tokens_total']}")
            print(f"      - Generation time: {row['generation_time_ms']} ms")
            print(f"      - PII detected: {row['pii_detected']}")
            print(f"      - Finish reason: {row['finish_reason']}")
            print(f"      - Error: {row['error_message'] or 'None'}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º chunks_data
            chunks_data = json.loads(row['chunks_data'])
            print(f"      - Chunks data: {len(chunks_data)} chunks")
            for i, chunk in enumerate(chunks_data, 1):
                print(f"        {i}. {chunk['question']} ({chunk['confidence']}%)")

    except Exception as e:
        print(f"   ‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        import traceback
        traceback.print_exc()
        return False

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ get_logs —Å LLM metadata
    print("\nüìä 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ get_logs() —Å LLM metadata...")
    try:
        logs = database.get_logs(filters={})

        # –ò—â–µ–º –Ω–∞—à—É —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–ø–∏—Å—å
        test_log = None
        for log in logs:
            if log.get('query_id') == query_log_id:
                test_log = log
                break

        if not test_log:
            print("   ‚ùå –û–®–ò–ë–ö–ê: –¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ get_logs()")
            return False

        if 'llm_metadata' not in test_log:
            print("   ‚ùå –û–®–ò–ë–ö–ê: llm_metadata –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ")
            return False

        llm_meta = test_log['llm_metadata']

        if not llm_meta:
            print("   ‚ùå –û–®–ò–ë–ö–ê: llm_metadata —Ä–∞–≤–µ–Ω NULL")
            return False

        print("   ‚úÖ LLM metadata –Ω–∞–π–¥–µ–Ω–∞ –≤ get_logs()")
        print(f"      - ID: {llm_meta['id']}")
        print(f"      - Model: {llm_meta['model']}")
        print(f"      - Chunks: {llm_meta['chunks_used']}")
        print(f"      - Tokens: {llm_meta['tokens']}")
        print(f"      - Chunks data: {len(llm_meta['chunks_data'])} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

    except Exception as e:
        print(f"   ‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ get_logs: {e}")
        import traceback
        traceback.print_exc()
        return False

    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print("\nüìà 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ RAG —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
    try:
        stats = database.get_statistics(filters={})

        if 'rag_answers' in stats:
            print(f"   ‚úÖ RAG —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–π–¥–µ–Ω–∞:")
            print(f"      - RAG answers: {stats['rag_answers']}")
            print(f"      - Avg tokens: {stats['rag_avg_tokens']}")
            print(f"      - Total tokens: {stats['rag_total_tokens']}")
            print(f"      - RAG errors: {stats['rag_errors']}")
        else:
            print("   ‚ùå –û–®–ò–ë–ö–ê: RAG —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ get_statistics()")
            return False

    except Exception as e:
        print(f"   ‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return False

    # 6. –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print("\nüßπ 6. –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    try:
        with database.get_db_connection() as conn:
            cursor = conn.cursor()

            # –£–¥–∞–ª—è–µ–º –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (–∏–∑-–∑–∞ FOREIGN KEY)
            cursor.execute("DELETE FROM llm_generations WHERE id = ?", (llm_gen_id,))
            cursor.execute("DELETE FROM answer_logs WHERE id = ?", (answer_log_id,))
            cursor.execute("DELETE FROM query_logs WHERE id = ?", (query_log_id,))

            conn.commit()
            print("   ‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª–µ–Ω—ã")

    except Exception as e:
        print(f"   ‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {e}")

    print("\n" + "=" * 60)
    print("‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!\n")
    return True


if __name__ == "__main__":
    success = test_rag_logging()
    sys.exit(0 if success else 1)
