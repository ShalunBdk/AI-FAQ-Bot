#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–∏–≤–æ–¥–∏—Ç —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º—ã —Å–ª–æ–≤
–∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è keyword search.
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PYTHONPATH
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.core.search import lemmatize_word, lemmatize_text, extract_keywords


def test_lemmatize_word():
    """–¢–µ—Å—Ç –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤"""
    print("=" * 60)
    print("–¢–ï–°–¢ 1: –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤")
    print("=" * 60)

    test_cases = [
        # –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ (—Ä–∞–∑–Ω—ã–µ –ø–∞–¥–µ–∂–∏)
        ("–ø—Ä–µ—Ç–µ–Ω–∑–∏—è", "–ø—Ä–µ—Ç–µ–Ω–∑–∏—è"),
        ("–ø—Ä–µ—Ç–µ–Ω–∑–∏—é", "–ø—Ä–µ—Ç–µ–Ω–∑–∏—è"),
        ("–ø—Ä–µ—Ç–µ–Ω–∑–∏–∏", "–ø—Ä–µ—Ç–µ–Ω–∑–∏—è"),
        ("–ø—Ä–µ—Ç–µ–Ω–∑–∏–π", "–ø—Ä–µ—Ç–µ–Ω–∑–∏—è"),

        # –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ/–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ)
        ("–∂–∞–ª–æ–±–∞", "–∂–∞–ª–æ–±–∞"),
        ("–∂–∞–ª–æ–±—É", "–∂–∞–ª–æ–±–∞"),
        ("–∂–∞–ª–æ–±—ã", "–∂–∞–ª–æ–±–∞"),

        ("–Ω–∞—Ä—É—à–µ–Ω–∏–µ", "–Ω–∞—Ä—É—à–µ–Ω–∏–µ"),
        ("–Ω–∞—Ä—É—à–µ–Ω–∏—è", "–Ω–∞—Ä—É—à–µ–Ω–∏–µ"),
        ("–Ω–∞—Ä—É—à–µ–Ω–∏–π", "–Ω–∞—Ä—É—à–µ–Ω–∏–µ"),

        ("—Ç–æ–≤–∞—Ä", "—Ç–æ–≤–∞—Ä"),
        ("—Ç–æ–≤–∞—Ä–∞", "—Ç–æ–≤–∞—Ä"),
        ("—Ç–æ–≤–∞—Ä—ã", "—Ç–æ–≤–∞—Ä"),

        # –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ
        ("–Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π", "–Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π"),
        ("–Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ", "–Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π"),
        ("–Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ", "–Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π"),

        ("–±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã–π", "–±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã–π"),
        ("–±—Ä–∞–∫–æ–≤–∞–Ω–Ω–æ–≥–æ", "–±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã–π"),
        ("–±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã–µ", "–±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã–π"),

        # –ì–ª–∞–≥–æ–ª—ã
        ("—Å–æ—Å—Ç–∞–≤–∏—Ç—å", "—Å–æ—Å—Ç–∞–≤–∏—Ç—å"),
        ("—Å–æ—Å—Ç–∞–≤–ª—é", "—Å–æ—Å—Ç–∞–≤–∏—Ç—å"),
        ("—Å–æ—Å—Ç–∞–≤–ª—è—é", "—Å–æ—Å—Ç–∞–≤–ª—è—Ç—å"),

        ("–ø–æ–≤—Ä–µ–¥–∏—Ç—å", "–ø–æ–≤—Ä–µ–¥–∏—Ç—å"),
        ("–ø–æ–≤—Ä–µ–¥–∏–ª", "–ø–æ–≤—Ä–µ–¥–∏—Ç—å"),
        ("–ø–æ–≤—Ä–µ–¥–∏–ª–∏", "–ø–æ–≤—Ä–µ–¥–∏—Ç—å"),
    ]

    passed = 0
    failed = 0

    for word, expected in test_cases:
        result = lemmatize_word(word)
        status = "‚úÖ" if result == expected else "‚ùå"

        if result == expected:
            passed += 1
        else:
            failed += 1

        print(f"{status} {word:20} ‚Üí {result:20} (–æ–∂–∏–¥–∞–ª–æ—Å—å: {expected})")

    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç: {passed} –ø—Ä–æ–π–¥–µ–Ω–æ, {failed} –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–æ")
    print()


def test_lemmatize_text():
    """–¢–µ—Å—Ç –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"""
    print("=" * 60)
    print("–¢–ï–°–¢ 2: –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞")
    print("=" * 60)

    test_cases = [
        "–ö–∞–∫ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–µ—Ç–µ–Ω–∑–∏—é?",
        "–£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º—ã —Å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º",
        "–Ø —Ö–æ—á—É –≤–µ—Ä–Ω—É—Ç—å –±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä",
        "–ù—É–∂–Ω–∞ —Å–ø—Ä–∞–≤–∫–∞ –æ –¥–æ—Ö–æ–¥–∞—Ö",
        "–ü–æ–≤—Ä–µ–¥–∏–ª–∏ —Ç–æ–≤–∞—Ä –ø—Ä–∏ –¥–æ—Å—Ç–∞–≤–∫–µ",
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –æ –≤–æ–∑–≤—Ä–∞—Ç–µ –¥–µ–Ω–µ–≥",
    ]

    for text in test_cases:
        lemmas = lemmatize_text(text)
        print(f"–¢–µ–∫—Å—Ç:  {text}")
        print(f"–õ–µ–º–º—ã: {lemmas}")
        print()


def test_extract_keywords():
    """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å/–±–µ–∑ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏"""
    print("=" * 60)
    print("–¢–ï–°–¢ 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
    print("=" * 60)

    test_cases = [
        "–ö–∞–∫ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–µ—Ç–µ–Ω–∑–∏—é –ø–æ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–º—É —Ç–æ–≤–∞—Ä—É?",
        "–£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º—ã —Å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ–º –∏ –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å",
        "–•–æ—á—É –ø–æ–¥–∞—Ç—å –∂–∞–ª–æ–±—É –Ω–∞ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞",
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –æ –≤–æ–∑–≤—Ä–∞—Ç–µ –¥–µ–Ω–µ–≥ –∑–∞ –±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä",
    ]

    for text in test_cases:
        print(f"–ó–∞–ø—Ä–æ—Å: {text}")
        print()

        # –ë–µ–∑ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏
        keywords_no_lemma = extract_keywords(text, use_lemmatization=False)
        print(f"  –ë–ï–ó –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏: {keywords_no_lemma}")

        # –° –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π
        keywords_with_lemma = extract_keywords(text, use_lemmatization=True)
        print(f"  –° –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π:  {keywords_with_lemma}")
        print()


def test_keyword_matching():
    """–¢–µ—Å—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ö"""
    print("=" * 60)
    print("–¢–ï–°–¢ 4: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
    print("=" * 60)

    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ FAQ (–Ω–∞—á–∞–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—ã)
    faq_keywords_raw = "–ø—Ä–µ—Ç–µ–Ω–∑–∏—è, –∂–∞–ª–æ–±–∞, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ, –Ω–∞—Ä—É—à–µ–Ω–∏–µ, —Ä–µ–∫–ª–∞–º–∞—Ü–∏—è, —Å–æ—Å—Ç–∞–≤–∏—Ç—å, –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, –ø–æ–≤—Ä–µ–¥–∏—Ç—å, –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ, –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–µ, –±–æ–π, –Ω–µ–¥–æ—Å—Ç–∞—á–∞, —Ç–æ–≤–∞—Ä, –±—Ä–∞–∫, –±—Ä–∞–∫–æ–≤–∞–Ω–Ω—ã–π, –ø–µ—Ä–µ–≤—ã—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, —à—Ç—Ä–∞—Ñ, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å, –≤–æ–∑–≤—Ä–∞—Ç"
    faq_keywords = extract_keywords(faq_keywords_raw, use_lemmatization=True)

    print(f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ FAQ (–ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ):")
    print(f"  {faq_keywords}")
    print()

    # –ó–∞–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ö
    user_queries = [
        "–ö–∞–∫ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–µ—Ç–µ–Ω–∑–∏—é?",
        "–ú–Ω–µ –Ω—É–∂–Ω–æ –ø–æ–¥–∞—Ç—å –∂–∞–ª–æ–±—É",
        "–£ –º–µ–Ω—è –ø–æ–≤—Ä–µ–¥–∏–ª–∏ —Ç–æ–≤–∞—Ä",
        "–•–æ—á—É –≤–µ—Ä–Ω—É—Ç—å –±—Ä–∞–∫–æ–≤–∞–Ω–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –æ –≤–æ–∑–≤—Ä–∞—Ç–µ –¥–µ–Ω–µ–≥",
    ]

    for query in user_queries:
        query_keywords = extract_keywords(query, use_lemmatization=True)

        # –ù–∞—Ö–æ–¥–∏–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        matches = [kw for kw in query_keywords if kw in faq_keywords]
        match_count = len(matches)

        print(f"–ó–∞–ø—Ä–æ—Å: {query}")
        print(f"  –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {query_keywords}")
        print(f"  –°–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å FAQ: {match_count}/{len(query_keywords)} ‚Üí {matches}")
        print()


if __name__ == "__main__":
    print("\nüî¨ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –õ–ï–ú–ú–ê–¢–ò–ó–ê–¶–ò–ò –ö–õ–Æ–ß–ï–í–´–• –°–õ–û–í\n")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ pymorphy3
    try:
        import pymorphy3
        print("‚úÖ pymorphy3 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n")
    except ImportError:
        print("‚ùå pymorphy3 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
        print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pymorphy3 pymorphy3-dicts-ru\n")
        sys.exit(1)

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    test_lemmatize_word()
    test_lemmatize_text()
    test_extract_keywords()
    test_keyword_matching()

    print("=" * 60)
    print("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print("=" * 60)
